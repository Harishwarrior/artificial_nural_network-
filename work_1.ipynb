{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
<<<<<<< HEAD
      "name": "work.ipynb",
      "provenance": []
=======
      "name": "work_1.ipynb",
      "provenance": [],
      "mount_file_id": "",
      "authorship_tag": "",
      "include_colab_link": true
>>>>>>> e08162e811b921090bb744f06acba950103950ce
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
<<<<<<< HEAD
        "id": "qDadTYaxHOu1",
        "colab_type": "text"
      },
      "source": [
        "To create a CNN using vgg16 model"
=======
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveenmarish/artificial_nural_network-/blob/master/work_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "P8pnDK8UueyW",
=======
        "id": "blvebtFDj5gh",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
<<<<<<< HEAD
        "from PIL import Image\n",
        "import os"
      ],
      "execution_count": null,
=======
        "from PIL import Image"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "YFs5DYZh5GoJ",
=======
        "id": "HqeHBnqGk05e",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "model = keras.applications.vgg16.VGG16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxig1KMo5cdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
=======
        "!ls\n",
        "%cd drive/My\\ Drive/project/Camera\\ Roll/"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "smGBD44c5xFh",
=======
        "id": "TxkXtdJSk56g",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "model_1 = keras.models.Sequential()\n",
        "for layer in model.layers:\n",
        "  model_1.add(layer)"
      ],
      "execution_count": null,
=======
        "!ls"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "Pq-_TfOb7c3Q",
=======
        "id": "hZiyUfP1k6wb",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "for layer in model_1.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
=======
        "train_dir='train'\n",
        "test_dir='validate'\n",
        "BATCH_SIZE=100\n",
        "IMG_SHAPE  = 224"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "UKA3uEMmAwvd",
=======
        "id": "DWoIAcq8k88z",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "model_1._layers.pop()"
      ],
      "execution_count": null,
=======
        "image_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
        "                                                         horizontal_flip=True,\n",
        "                                                         rotation_range=45,\n",
        "                                                         width_shift_range=.15,\n",
        "                                                         height_shift_range=.15,\n",
        "                                                         zoom_range=0.5)\n",
        "\n",
        "train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                               class_mode='sparse')"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "jnvG50QQ7xsl",
=======
        "id": "w8ChJQqfk_p2",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiOcl55IHZoV",
        "colab_type": "text"
      },
      "source": [
        "Give the number of class your going to use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivRk7OV38fa2",
=======
        "image_gen_val = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validate_data_gen=image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                directory=test_dir,\n",
        "                                                shuffle=True,\n",
        "                                                target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                class_mode='sparse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI-F8VKNoZex",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "model_1.add(keras.layers.Dense(2,activation=\"softmax\"))"
      ],
      "execution_count": null,
=======
        "total_train=7\n",
        "total_validate=3"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "nci81CVnAP9F",
=======
        "id": "WRHTzaO57jt4",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "model_1.summary()"
      ],
      "execution_count": null,
=======
        "model_2 = keras.models.Sequential()\n",
        "\n",
        "model_2.add(keras.layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_SHAPE,IMG_SHAPE, 3)))\n",
        "model_2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model_2.add(keras.layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
        "model_2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model_2.add(keras.layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
        "model_2.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model_2.add(keras.layers.Flatten())\n",
        "model_2.add(keras.layers.Dropout(0.2))\n",
        "model_2.add(keras.layers.Dense(512, activation='relu'))\n",
        "\n",
        "model_2.add(keras.layers.Dropout(0.2))\n",
        "model_2.add(keras.layers.Dense(2))"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "r0EbfgN67ADw",
=======
        "id": "JZl-L1Dz8QIK",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Bbr44vKHrMB",
        "colab_type": "text"
      },
      "source": [
        "Save the image set in drive/My Drive/project/Camera Roll within a folder with the name of class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg_o6pPDQ2sw",
=======
        "model_2.compile(optimizer='adam',\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J97-LPIilC1e",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "!ls\n",
        "%cd drive/My\\ Drive/project/Camera\\ Roll/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZuSuJOVHyQG",
        "colab_type": "text"
      },
      "source": [
        "Give the names of image sets given as name of folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEqs3DEUHzbt",
=======
        "epochs=40\n",
        "history = model_2.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
        "    epochs=epochs,\n",
        "    validation_data=validate_data_gen,\n",
        "    validation_steps=int(np.ceil(total_validate / float(BATCH_SIZE)))\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUZyhwXhlJKY",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "classes = []"
      ],
      "execution_count": null,
=======
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "7ie2pKyNIHXS",
=======
        "id": "Okxv3xjLpeIi",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "for cl in classes:\n",
        "  img_path = os.path.join(base_dir, cl)\n",
        "  images = glob.glob(img_path + '/*.jpg')\n",
        "  print(\"{}: {} Images\".format(cl, len(images)))\n",
        "  num_train = int(round(len(images)*0.8))\n",
        "  train, val = images[:num_train], images[num_train:]\n",
        "\n",
        "  for t in train:\n",
        "    if not os.path.exists(os.path.join(base_dir, 'train', cl)):\n",
        "      os.makedirs(os.path.join(base_dir, 'train', cl))\n",
        "    shutil.move(t, os.path.join(base_dir, 'train', cl))\n",
        "\n",
        "  for v in val:\n",
        "    if not os.path.exists(os.path.join(base_dir, 'val', cl)):\n",
        "      os.makedirs(os.path.join(base_dir, 'val', cl))\n",
        "    shutil.move(v, os.path.join(base_dir, 'val', cl))"
      ],
      "execution_count": null,
=======
        "!ls\n",
        "result=None"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "w0HdCYTeSVJs",
=======
        "id": "OYDXpav9py5s",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "!ls"
      ],
      "execution_count": null,
=======
        "test = image_gen.flow_from_directory(directory=\"test\",\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     target_size=(IMG_SHAPE,IMG_SHAPE))"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "ubb0iNdM8IxU",
=======
        "id": "fTJ4EmLdp1eq",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "train_dir='train'\n",
        "test_dir='validate'\n",
        "BATCH_SIZE=100\n",
        "IMG_SHAPE  = 224"
      ],
      "execution_count": null,
=======
        "result=model_1.predict(test)"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "uMHHGjtgOKDl",
=======
        "id": "BizqwPBsp4F5",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "image_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
        "                                                         horizontal_flip=True,\n",
        "                                                         rotation_range=45,\n",
        "                                                         width_shift_range=.15,\n",
        "                                                         height_shift_range=.15,\n",
        "                                                         zoom_range=0.5)\n",
        "\n",
        "train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_SHAPE,IMG_SHAPE))"
      ],
      "execution_count": null,
=======
        "print(result)"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "M05LBoteUsRO",
=======
        "id": "0mIeMz5G917K",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "image_gen_val = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validate_data_gen=image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                directory=test_dir,\n",
        "                                                shuffle=True,\n",
        "                                                target_size=(IMG_SHAPE,IMG_SHAPE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZRqrS4lIOh1",
        "colab_type": "text"
      },
      "source": [
        "Give the number of train and validate images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJZZeOpxKvJJ",
=======
        "print(test)\n",
        "plt.plot(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly3tia4z_b1u",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "total_train=7\n",
        "total_valid=3"
      ],
      "execution_count": null,
=======
        "!ls"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "-S-pVp5AV0uN",
=======
        "id": "AnMwrSsK_eK8",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "epochs=100\n",
        "history = model_1.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
        "    epochs=epochs,\n",
        "    validation_data=validate_data_gen,\n",
        "    validation_steps=int(np.ceil(total_valid / float(BATCH_SIZE)))\n",
        ")"
      ],
      "execution_count": null,
=======
        "%cd train/marish/"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "1DRumR1WYehb",
=======
        "id": "3DBKpaTj_joP",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
=======
        "!ls"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "qRpg-fJfffmr",
=======
        "id": "wlH5BmHJ-ZOR",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMFnzWNUIiAj",
        "colab_type": "text"
      },
      "source": [
        "Create test folder for test the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hepaBqfJwmcQ",
=======
        "image=Image.open(\"WIN_20200514_12_02_24_Pro.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUJ1p5MwCfNe",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "test = image_gen.flow_from_directory(directory=\"test\",\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     target_size=(IMG_SHAPE,IMG_SHAPE))"
      ],
      "execution_count": null,
=======
        "imsize=(224,224)\n",
        "image=image.resize(imsize)"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "UO2Ft7Lvxpp4",
=======
        "id": "AbTFPyNKC_yJ",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "result=model_1.predict(test)"
      ],
      "execution_count": null,
=======
        "image=keras.preprocessing.image.img_to_array(image)"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "gbcawCCSyBLX",
=======
        "id": "4nfmfUwBDuWD",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "result.shape"
      ],
      "execution_count": null,
=======
        "image=np.expand_dims(image,axis=0)"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "k3AOz2HDyJLX",
=======
        "id": "nIydkaW8D_SN",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "result[0]"
      ],
      "execution_count": null,
=======
        "result=model_2.predict(image)"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "-eGE2zhWyWt_",
=======
        "id": "SMnzb5YWEIjE",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "np.argmax(result[0])"
      ],
      "execution_count": null,
=======
        "print(result)"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
<<<<<<< HEAD
        "id": "JTeIHoVnylEF",
=======
        "id": "XrnFz3DOEPdk",
>>>>>>> e08162e811b921090bb744f06acba950103950ce
        "colab_type": "code",
        "colab": {}
      },
      "source": [
<<<<<<< HEAD
        "print(result)"
      ],
      "execution_count": null,
=======
        "result[0]"
      ],
      "execution_count": 0,
>>>>>>> e08162e811b921090bb744f06acba950103950ce
      "outputs": []
    }
  ]
}